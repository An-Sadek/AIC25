import torch
from transformers import AutoProcessor, Qwen2VLForConditionalGeneration
from PIL import Image

# Thi·∫øt b·ªã
device = "cpu"
model_id = "Qwen/Qwen2-VL-2B-Instruct"

# Load model tr√™n CPU
model = Qwen2VLForConditionalGeneration.from_pretrained(
    model_id,
    torch_dtype=torch.float32,
    low_cpu_mem_usage=True
).to(device)

processor = AutoProcessor.from_pretrained(model_id)

# ƒê·ªçc ·∫£nh t·ª´ ƒë∆∞·ªùng d·∫´n
image_path = "test/sakura.jpg"
try:
    image = Image.open(image_path).convert("RGB")  # Chuy·ªÉn ·∫£nh sang ƒë·ªãnh d·∫°ng RGB
except FileNotFoundError:
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file ·∫£nh t·∫°i: {image_path}")

# Prompt
messages = [
    {
        "role": "user",
        "content": [
            {"type": "image", "image": image},  # Truy·ªÅn ƒë·ªëi t∆∞·ª£ng PIL.Image
            {"type": "text", "text": "M√¥ t·∫£ b·ª©c ·∫£nh n√†y b·∫±ng ti·∫øng Vi·ªát th·∫≠t chi ti·∫øt, s√∫c t√≠ch."}
        ]
    }
]

# T·∫°o input b·∫±ng c√°ch s·ª≠ d·ª•ng apply_chat_template
chat_template = processor.apply_chat_template(messages, add_generation_prompt=True)
inputs = processor(
    text=chat_template,  # Truy·ªÅn template ƒë√£ x·ª≠ l√Ω
    images=[image],  # Truy·ªÅn danh s√°ch ·∫£nh
    return_tensors="pt"
).to(device)

# Sinh m√¥ t·∫£
generated = model.generate(**inputs, max_new_tokens=128)
output = processor.batch_decode(generated, skip_special_tokens=True)[0]
print("üëâ M√¥ t·∫£ ·∫£nh:", output)